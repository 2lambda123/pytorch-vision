{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Visualization utilities\n\nThis example illustrates some of the utilities that torchvision offers for\nvisualizing images, bounding boxes, and segmentation masks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport numpy as np\nimport scipy.misc\nimport matplotlib.pyplot as plt\n\nimport torchvision.transforms.functional as F\n\n\nplt.rcParams[\"savefig.bbox\"] = 'tight'\n\n\ndef show(imgs):\n    if not isinstance(imgs, list):\n        imgs = [imgs]\n    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n    for i, img in enumerate(imgs):\n        img = F.to_pil_image(img.to('cpu'))\n        axs[0, i].imshow(np.asarray(img))\n        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing a grid of images\nThe :func:`~torchvision.utils.make_grid` function can be used to create a\ntensor that represents multiple images in a grid.  This util requires a single\nimage of dtype ``uint8`` as input.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\nfrom torchvision.io import read_image\nfrom pathlib import Path\n\ndog1_int = read_image(str(Path('assets') / 'dog1.jpg'))\ndog2_int = read_image(str(Path('assets') / 'dog2.jpg'))\n\ngrid = make_grid([dog1_int, dog2_int, dog1_int, dog2_int])\nshow(grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing bounding boxes\nWe can use :func:`~torchvision.utils.draw_bounding_boxes` to draw boxes on an\nimage. We can set the colors, labels, width as well as font and font size !\nThe boxes are in ``(xmin, ymin, xmax, ymax)`` format\nfrom torchvision.utils import draw_bounding_boxes\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import draw_bounding_boxes\n\n\nboxes = torch.tensor([[50, 50, 100, 200], [210, 150, 350, 430]], dtype=torch.float)\ncolors = [\"blue\", \"yellow\"]\nresult = draw_bounding_boxes(dog1_int, boxes, colors=colors, width=5)\nshow(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Naturally, we can also plot bounding boxes produced by torchvision detection\nmodels.  Here is demo with a Faster R-CNN model loaded from\n:func:`~torchvision.models.detection.fasterrcnn_resnet50_fpn`\nmodel. You can also try using a RetinaNet with\n:func:`~torchvision.models.detection.retinanet_resnet50_fpn`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.transforms.functional import convert_image_dtype\n\n\ndog1_float = convert_image_dtype(dog1_int, dtype=torch.float)\ndog2_float = convert_image_dtype(dog2_int, dtype=torch.float)\nbatch = torch.stack([dog1_float, dog2_float])\n\nmodel = fasterrcnn_resnet50_fpn(pretrained=True, progress=False)\nmodel = model.eval()\n\noutputs = model(batch)\nprint(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the boxes detected by our model. We will only plot the boxes with a\nscore greater than a given threshold.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "threshold = .8\ndogs_with_boxes = [\n    draw_bounding_boxes(dog_int, boxes=output['boxes'][output['scores'] > threshold], width=4)\n    for dog_int, output in zip((dog1_int, dog2_int), outputs)\n]\nshow(dogs_with_boxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing segmentation masks\nThe :func:`~torchvision.utils.draw_segmentation_masks` function can be used to\ndraw segmentation amasks on images. We can set the colors as well as\ntransparency of masks.\n\nHere is demo with torchvision's FCN Resnet-50, loaded with\n:func:`~torchvision.models.segmentation.fcn_resnet50`.\nYou can also try using\nDeepLabv3 (:func:`~torchvision.models.segmentation.deeplabv3_resnet50`)\nor lraspp mobilenet models\n(:func:`~torchvision.models.segmentation.lraspp_mobilenet_v3_large`).\n\nLike :func:`~torchvision.utils.draw_bounding_boxes`,\n:func:`~torchvision.utils.draw_segmentation_masks` requires a single RGB image\nof dtype `uint8`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchvision.models.segmentation import fcn_resnet50\nfrom torchvision.utils import draw_segmentation_masks\n\n\nmodel = fcn_resnet50(pretrained=True, progress=False)\nmodel = model.eval()\n\n# The model expects the batch to be normalized\nbatch = F.normalize(batch, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\noutputs = model(batch)\n\ndogs_with_masks = [\n    draw_segmentation_masks(dog_int, masks=masks, alpha=0.6)\n    for dog_int, masks in zip((dog1_int, dog2_int), outputs['out'])\n]\nshow(dogs_with_masks)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/plot_visualization_utils.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_plot_visualization_utils.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_plot_visualization_utils.py:


=======================
Visualization utilities
=======================

This example illustrates some of the utilities that torchvision offers for
visualizing images, bounding boxes, and segmentation masks.

.. GENERATED FROM PYTHON SOURCE LINES 9-32

.. code-block:: default



    import torch
    import numpy as np
    import scipy.misc
    import matplotlib.pyplot as plt

    import torchvision.transforms.functional as F


    plt.rcParams["savefig.bbox"] = 'tight'


    def show(imgs):
        if not isinstance(imgs, list):
            imgs = [imgs]
        fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)
        for i, img in enumerate(imgs):
            img = F.to_pil_image(img.to('cpu'))
            axs[0, i].imshow(np.asarray(img))
            axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])









.. GENERATED FROM PYTHON SOURCE LINES 33-38

Visualizing a grid of images
----------------------------
The :func:`~torchvision.utils.make_grid` function can be used to create a
tensor that represents multiple images in a grid.  This util requires a single
image of dtype ``uint8`` as input.

.. GENERATED FROM PYTHON SOURCE LINES 38-49

.. code-block:: default


    from torchvision.utils import make_grid
    from torchvision.io import read_image
    from pathlib import Path

    dog1_int = read_image(str(Path('assets') / 'dog1.jpg'))
    dog2_int = read_image(str(Path('assets') / 'dog2.jpg'))

    grid = make_grid([dog1_int, dog2_int, dog1_int, dog2_int])
    show(grid)




.. image:: /auto_examples/images/sphx_glr_plot_visualization_utils_001.png
    :alt: plot visualization utils
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 50-56

Visualizing bounding boxes
--------------------------
We can use :func:`~torchvision.utils.draw_bounding_boxes` to draw boxes on an
image. We can set the colors, labels, width as well as font and font size !
The boxes are in ``(xmin, ymin, xmax, ymax)`` format
from torchvision.utils import draw_bounding_boxes

.. GENERATED FROM PYTHON SOURCE LINES 56-66

.. code-block:: default


    from torchvision.utils import draw_bounding_boxes


    boxes = torch.tensor([[50, 50, 100, 200], [210, 150, 350, 430]], dtype=torch.float)
    colors = ["blue", "yellow"]
    result = draw_bounding_boxes(dog1_int, boxes, colors=colors, width=5)
    show(result)





.. image:: /auto_examples/images/sphx_glr_plot_visualization_utils_002.png
    :alt: plot visualization utils
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 67-72

Naturally, we can also plot bounding boxes produced by torchvision detection
models.  Here is demo with a Faster R-CNN model loaded from
:func:`~torchvision.models.detection.fasterrcnn_resnet50_fpn`
model. You can also try using a RetinaNet with
:func:`~torchvision.models.detection.retinanet_resnet50_fpn`.

.. GENERATED FROM PYTHON SOURCE LINES 72-87

.. code-block:: default


    from torchvision.models.detection import fasterrcnn_resnet50_fpn
    from torchvision.transforms.functional import convert_image_dtype


    dog1_float = convert_image_dtype(dog1_int, dtype=torch.float)
    dog2_float = convert_image_dtype(dog2_int, dtype=torch.float)
    batch = torch.stack([dog1_float, dog2_float])

    model = fasterrcnn_resnet50_fpn(pretrained=True, progress=False)
    model = model.eval()

    outputs = model(batch)
    print(outputs)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading: "https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth
    /root/project/env/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1620803180156/work/c10/core/TensorImpl.h:1156.)
      return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
    [{'boxes': tensor([[215.9767, 171.1661, 402.0078, 378.7391],
            [344.6341, 172.6735, 357.6114, 220.1435],
            [153.1306, 185.5568, 172.9223, 254.7014]], grad_fn=<StackBackward>), 'labels': tensor([18,  1,  1]), 'scores': tensor([0.9989, 0.0701, 0.0611], grad_fn=<IndexBackward>)}, {'boxes': tensor([[ 23.5963, 132.4332, 449.9359, 493.0222],
            [225.8183, 124.6292, 467.2861, 492.2621],
            [ 18.5249, 135.4171, 420.9786, 479.2226]], grad_fn=<StackBackward>), 'labels': tensor([18, 18, 17]), 'scores': tensor([0.9980, 0.0879, 0.0671], grad_fn=<IndexBackward>)}]




.. GENERATED FROM PYTHON SOURCE LINES 88-90

Let's plot the boxes detected by our model. We will only plot the boxes with a
score greater than a given threshold.

.. GENERATED FROM PYTHON SOURCE LINES 90-98

.. code-block:: default


    threshold = .8
    dogs_with_boxes = [
        draw_bounding_boxes(dog_int, boxes=output['boxes'][output['scores'] > threshold], width=4)
        for dog_int, output in zip((dog1_int, dog2_int), outputs)
    ]
    show(dogs_with_boxes)




.. image:: /auto_examples/images/sphx_glr_plot_visualization_utils_003.png
    :alt: plot visualization utils
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 99-115

Visualizing segmentation masks
------------------------------
The :func:`~torchvision.utils.draw_segmentation_masks` function can be used to
draw segmentation amasks on images. We can set the colors as well as
transparency of masks.

Here is demo with torchvision's FCN Resnet-50, loaded with
:func:`~torchvision.models.segmentation.fcn_resnet50`.
You can also try using
DeepLabv3 (:func:`~torchvision.models.segmentation.deeplabv3_resnet50`)
or lraspp mobilenet models
(:func:`~torchvision.models.segmentation.lraspp_mobilenet_v3_large`).

Like :func:`~torchvision.utils.draw_bounding_boxes`,
:func:`~torchvision.utils.draw_segmentation_masks` requires a single RGB image
of dtype `uint8`.

.. GENERATED FROM PYTHON SOURCE LINES 115-132

.. code-block:: default


    from torchvision.models.segmentation import fcn_resnet50
    from torchvision.utils import draw_segmentation_masks


    model = fcn_resnet50(pretrained=True, progress=False)
    model = model.eval()

    # The model expects the batch to be normalized
    batch = F.normalize(batch, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
    outputs = model(batch)

    dogs_with_masks = [
        draw_segmentation_masks(dog_int, masks=masks, alpha=0.6)
        for dog_int, masks in zip((dog1_int, dog2_int), outputs['out'])
    ]
    show(dogs_with_masks)



.. image:: /auto_examples/images/sphx_glr_plot_visualization_utils_004.png
    :alt: plot visualization utils
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Downloading: "https://download.pytorch.org/models/fcn_resnet50_coco-1167a1af.pth" to /root/.cache/torch/hub/checkpoints/fcn_resnet50_coco-1167a1af.pth





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  6.077 seconds)


.. _sphx_glr_download_auto_examples_plot_visualization_utils.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_visualization_utils.py <plot_visualization_utils.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_visualization_utils.ipynb <plot_visualization_utils.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_

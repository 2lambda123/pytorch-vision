# THIS FILE IS AUTOGENERATED
#
# FROM torchvision/prototype/transforms/functional/dispatch.yaml
# WITH scripts/regenerate_transforms_dispatch.py
#
# DO NOT CHANGE MANUALLY!

from typing import Any, TypeVar, List, Optional, Tuple

import torch
import torchvision.prototype.transforms.functional as F
import torchvision.transforms.functional as _F
from torchvision.prototype import features
from torchvision.prototype.features import BoundingBoxFormat, ColorSpace
from torchvision.transforms import InterpolationMode

Dispatcher = F.utils.Dispatcher

# This is just a sentinel to have a default argument for a dispatcher if the feature specific implementations use
# different defaults. The actual value is never used.
FEATURE_SPECIFIC_DEFAULT = object()

T = TypeVar("T", bound=features.Feature)


__all__ = [
    "horizontal_flip",
    "resize",
    "center_crop",
    "normalize",
    "resized_crop",
    "erase",
    "mixup",
    "cutmix",
    "affine",
    "rotate",
    "adjust_brightness",
    "adjust_saturation",
    "adjust_contrast",
    "adjust_sharpness",
    "posterize",
    "solarize",
    "autocontrast",
    "equalize",
    "invert",
]


@Dispatcher
def horizontal_flip(input: T) -> T:
    """ADDME"""
    pass


@horizontal_flip.implements(features.Image)
def _horizontal_flip_image(input: features.Image) -> features.Image:
    output = F.horizontal_flip_image(input)

    return features.Image.new_like(input, output)


@horizontal_flip.implements(features.BoundingBox)
def _horizontal_flip_bounding_box(input: features.BoundingBox) -> features.BoundingBox:
    intermediate_format = BoundingBoxFormat.XYXY
    converted_input = F.convert_bounding_box_format(input, old_format=input.format, new_format=intermediate_format)

    output = F.horizontal_flip_bounding_box(converted_input, image_size=input.image_size)
    output = F.convert_bounding_box_format(output, old_format=intermediate_format, new_format=input.format)

    return features.BoundingBox.new_like(input, output)


@Dispatcher
def resize(
    input: T,
    *,
    size: List[int],
    interpolation: InterpolationMode = FEATURE_SPECIFIC_DEFAULT,  # type: ignore[assignment]
    max_size: Optional[int] = None,
    antialias: Optional[bool] = None,
) -> T:
    """ADDME"""
    pass


@resize.implements(features.Image, pil_kernel=_F.resize)
def _resize_image(
    input: features.Image,
    *,
    size: List[int],
    interpolation: InterpolationMode = InterpolationMode.BILINEAR,
    max_size: Optional[int] = None,
    antialias: Optional[bool] = None,
) -> features.Image:
    output = F.resize_image(input, size=size, interpolation=interpolation, max_size=max_size, antialias=antialias)

    return features.Image.new_like(input, output)


@resize.implements(features.BoundingBox)
def _resize_bounding_box(input: features.BoundingBox, *, size: List[int], **_: Any) -> features.BoundingBox:
    intermediate_format = BoundingBoxFormat.XYXY
    converted_input = F.convert_bounding_box_format(input, old_format=input.format, new_format=intermediate_format)

    output = F.resize_bounding_box(converted_input, old_image_size=input.image_size, new_image_size=size)
    output = F.convert_bounding_box_format(output, old_format=intermediate_format, new_format=input.format)

    return features.BoundingBox.new_like(input, output, image_size="size")


@resize.implements(features.SegmentationMask)
def _resize_segmentation_mask(
    input: features.SegmentationMask,
    *,
    size: List[int],
    interpolation: InterpolationMode = InterpolationMode.NEAREST,
    max_size: Optional[int] = None,
    antialias: Optional[bool] = None,
) -> features.SegmentationMask:
    output = F.resize_segmentation_mask(
        input, size=size, interpolation=interpolation, max_size=max_size, antialias=antialias
    )

    return features.SegmentationMask.new_like(input, output)


@Dispatcher
def center_crop(input: T, *, output_size: List[int]) -> T:
    """ADDME"""
    pass


@center_crop.implements(features.Image, pil_kernel=_F.center_crop)
def _center_crop_image(input: features.Image, *, output_size: List[int]) -> features.Image:
    output = F.center_crop(input, output_size=output_size)

    return features.Image.new_like(input, output)


@Dispatcher
def normalize(input: T, *, mean: List[float], std: List[float], inplace: bool = False) -> T:
    """ADDME"""
    pass


@normalize.implements(features.Image)
def _normalize_image(
    input: features.Image, *, mean: List[float], std: List[float], inplace: bool = False
) -> features.Image:
    output = F.normalize(input, mean=mean, std=std, inplace=inplace)

    return features.Image.new_like(input, output, color_space=ColorSpace.OTHER)


@Dispatcher
def resized_crop(
    input: T,
    *,
    top: int,
    left: int,
    height: int,
    width: int,
    size: List[int],
    interpolation: InterpolationMode = InterpolationMode.BILINEAR,
) -> T:
    """ADDME"""
    pass


@resized_crop.implements(features.Image, pil_kernel=_F.resized_crop)
def _resized_crop_image(
    input: features.Image,
    *,
    top: int,
    left: int,
    height: int,
    width: int,
    size: List[int],
    interpolation: InterpolationMode = InterpolationMode.BILINEAR,
) -> features.Image:
    output = F.resized_crop(
        input, top=top, left=left, height=height, width=width, size=size, interpolation=interpolation
    )

    return features.Image.new_like(input, output)


@Dispatcher
def erase(input: T, *, i: int, j: int, h: int, w: int, v: torch.Tensor, inplace: bool = False) -> T:
    """ADDME"""
    pass


@erase.implements(features.Image, pil_kernel=_F.erase)
def _erase_image(
    input: features.Image, *, i: int, j: int, h: int, w: int, v: torch.Tensor, inplace: bool = False
) -> features.Image:
    output = F.erase(input, i=i, j=j, h=h, w=w, v=v, inplace=inplace)

    return features.Image.new_like(input, output)


@Dispatcher
def mixup(input: T, *, lam: float, inplace: bool = False) -> T:
    """ADDME"""
    pass


@mixup.implements(features.Image)
def _mixup_image(input: features.Image, *, lam: float, inplace: bool = False) -> features.Image:
    output = F.mixup_image(input, lam=lam, inplace=inplace)

    return features.Image.new_like(input, output)


@mixup.implements(features.OneHotLabel)
def _mixup_one_hot_label(input: features.OneHotLabel, *, lam: float, inplace: bool = False) -> features.OneHotLabel:
    output = F.mixup_one_hot_label(input, lam=lam, inplace=inplace)

    return features.OneHotLabel.new_like(input, output)


@Dispatcher
def cutmix(
    input: T,
    *,
    box: Tuple[int, int, int, int] = Dispatcher.FEATURE_SPECIFIC_PARAM,  # type: ignore[assignment]
    lam_adjusted: float = Dispatcher.FEATURE_SPECIFIC_PARAM,  # type: ignore[assignment]
    inplace: bool = False,
) -> T:
    """ADDME"""
    pass


@cutmix.implements(features.Image, feature_specific_params=("box",))
def _cutmix_image(
    input: features.Image, *, box: Tuple[int, int, int, int], inplace: bool = False, **_: Any
) -> features.Image:
    output = F.cutmix_image(input, box=box, inplace=inplace)

    return features.Image.new_like(input, output)


@cutmix.implements(features.OneHotLabel, feature_specific_params=("lam_adjusted",))
def _cutmix_one_hot_label(
    input: features.OneHotLabel, *, lam_adjusted: float, inplace: bool = False, **_: Any
) -> features.OneHotLabel:
    output = F.cutmix_one_hot_label(input, lam_adjusted=lam_adjusted, inplace=inplace)

    return features.OneHotLabel.new_like(input, output)


@Dispatcher
def affine(
    input: T,
    *,
    angle: float,
    translate: List[int],
    scale: float,
    shear: List[float],
    interpolation: InterpolationMode = InterpolationMode.NEAREST,
    fill: Optional[List[float]] = None,
    resample: Optional[int] = None,
    fillcolor: Optional[List[float]] = None,
    center: Optional[List[int]] = None,
) -> T:
    """ADDME"""
    pass


@affine.implements(features.Image, pil_kernel=_F.affine)
def _affine_image(
    input: features.Image,
    *,
    angle: float,
    translate: List[int],
    scale: float,
    shear: List[float],
    interpolation: InterpolationMode = InterpolationMode.NEAREST,
    fill: Optional[List[float]] = None,
    resample: Optional[int] = None,
    fillcolor: Optional[List[float]] = None,
    center: Optional[List[int]] = None,
) -> features.Image:
    output = F.affine(
        input,
        angle=angle,
        translate=translate,
        scale=scale,
        shear=shear,
        interpolation=interpolation,
        fill=fill,
        resample=resample,
        fillcolor=fillcolor,
        center=center,
    )

    return features.Image.new_like(input, output)


@Dispatcher
def rotate(
    input: T,
    *,
    angle: float,
    interpolation: InterpolationMode = InterpolationMode.NEAREST,
    expand: bool = False,
    center: Optional[List[int]] = None,
    fill: Optional[List[float]] = None,
    resample: Optional[int] = None,
) -> T:
    """ADDME"""
    pass


@rotate.implements(features.Image, pil_kernel=_F.rotate)
def _rotate_image(
    input: features.Image,
    *,
    angle: float,
    interpolation: InterpolationMode = InterpolationMode.NEAREST,
    expand: bool = False,
    center: Optional[List[int]] = None,
    fill: Optional[List[float]] = None,
    resample: Optional[int] = None,
) -> features.Image:
    output = F.rotate(
        input, angle=angle, interpolation=interpolation, expand=expand, center=center, fill=fill, resample=resample
    )

    return features.Image.new_like(input, output)


@Dispatcher
def adjust_brightness(input: T, *, brightness_factor: float) -> T:
    """ADDME"""
    pass


@adjust_brightness.implements(features.Image, pil_kernel=_F.adjust_brightness)
def _adjust_brightness_image(input: features.Image, *, brightness_factor: float) -> features.Image:
    output = F.adjust_brightness(input, brightness_factor=brightness_factor)

    return features.Image.new_like(input, output)


@Dispatcher
def adjust_saturation(input: T, *, saturation_factor: float) -> T:
    """ADDME"""
    pass


@adjust_saturation.implements(features.Image, pil_kernel=_F.adjust_saturation)
def _adjust_saturation_image(input: features.Image, *, saturation_factor: float) -> features.Image:
    output = F.adjust_saturation(input, saturation_factor=saturation_factor)

    return features.Image.new_like(input, output)


@Dispatcher
def adjust_contrast(input: T, *, contrast_factor: float) -> T:
    """ADDME"""
    pass


@adjust_contrast.implements(features.Image, pil_kernel=_F.adjust_contrast)
def _adjust_contrast_image(input: features.Image, *, contrast_factor: float) -> features.Image:
    output = F.adjust_contrast(input, contrast_factor=contrast_factor)

    return features.Image.new_like(input, output)


@Dispatcher
def adjust_sharpness(input: T, *, sharpness_factor: float) -> T:
    """ADDME"""
    pass


@adjust_sharpness.implements(features.Image, pil_kernel=_F.adjust_sharpness)
def _adjust_sharpness_image(input: features.Image, *, sharpness_factor: float) -> features.Image:
    output = F.adjust_sharpness(input, sharpness_factor=sharpness_factor)

    return features.Image.new_like(input, output)


@Dispatcher
def posterize(input: T, *, bits: int) -> T:
    """ADDME"""
    pass


@posterize.implements(features.Image, pil_kernel=_F.posterize)
def _posterize_image(input: features.Image, *, bits: int) -> features.Image:
    output = F.posterize(input, bits=bits)

    return features.Image.new_like(input, output)


@Dispatcher
def solarize(input: T, *, threshold: float) -> T:
    """ADDME"""
    pass


@solarize.implements(features.Image, pil_kernel=_F.solarize)
def _solarize_image(input: features.Image, *, threshold: float) -> features.Image:
    output = F.solarize(input, threshold=threshold)

    return features.Image.new_like(input, output)


@Dispatcher
def autocontrast(input: T) -> T:
    """ADDME"""
    pass


@autocontrast.implements(features.Image, pil_kernel=_F.autocontrast)
def _autocontrast_image(input: features.Image) -> features.Image:
    output = F.autocontrast(input)

    return features.Image.new_like(input, output)


@Dispatcher
def equalize(input: T) -> T:
    """ADDME"""
    pass


@equalize.implements(features.Image, pil_kernel=_F.equalize)
def _equalize_image(input: features.Image) -> features.Image:
    output = F.equalize(input)

    return features.Image.new_like(input, output)


@Dispatcher
def invert(input: T) -> T:
    """ADDME"""
    pass


@invert.implements(features.Image, pil_kernel=_F.invert)
def _invert_image(input: features.Image) -> features.Image:
    output = F.invert(input)

    return features.Image.new_like(input, output)
